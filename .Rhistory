fit<-train(y~.,data=vowel.train,method="rf",prox=T)
rfNews()
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
fit<-train(y~.,data=vowel.train,method="rf",prox=T)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
fit<-train(y~.,data=vowel.train,method="rf",prox=T)
?varlamp
?varlmp
?varImp
varImp.randomForest(fit)
varImp(fit)
library(randomForest)
?randomForest
fit5<-randomForest(y~.,data=vowel.train)
importance(fit5)
?importance
importance(fit5,1)
importance(fit5,type=2)
order(importance(fit5,type=2))
order(importance(fit5,type=2),decreasing=F)
order(importance(fit5,type=2),decreasing=T)
varImp(fit,type=2)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
fit5<-train(y~.,data=vowel.train,method="rf",prox=T)
library(caret)
fit1<-train(y~.,data=vowel.train,method="rf",prox=T)
fit2<-train(y~.,data=vowel.train,method="gbm",verbose=F)
fit2<-train(y~.,data=vowel.train,method="gbm",verbose=F)
View(vowel.test)
confusionMatrix(vowel.test$y,predict(fit1,vowel.test))
confusionMatrix(vowel.test$y,predict(fit2,vowel.test))
confusionMatrix(predict(fit1,vowel.test),predict(fit2,vowel.test))
?confusionMatrix
confusionMatrix(vowel.test$y,predict(fit2,vowel.test))$overall
confusionMatrix(vowel.test$y,predict(fit1,vowel.test))$overall
confusionMatrix(vowel.test$y,predict(fit2,vowel.test))$overall
confusionMatrix(predict(fit1,vowel.test),predict(fit2,vowel.test))$overall
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(testing)
fitrf<-train(diagnosis~.,data=training,method="rf",prox=T)
fitgbm<-train(diagnosis~.,data=training,method="gbm",verbose=F)
fitlda<-train(diagnosis~.,data=training,method="lda")
predrf<-predict(fitrf,testing)
head(predrf)
predgbm<-predcit(fitgbm,testing)
predgbm<-predict(fitgbm,testing)
predlda<-predcit(fitlda,testing)
predlda<-predict(fitlda,testing)
predcomb<-data.frame(predrf,predgbm,predlda,diagnosis=testing$diagnosis)
View(predcomb)
combFit<-train(diagnosis~.,data=predcomb,method="rf")
combPred<-predict(combFit,predcomb)
confusionMatrix(combPred,testing$diagnosis)
confusionMatrix(predrf,testing$diagnosis)$overall
confusionMatrix(predgbm,testing$diagnosis)$overall
confusionMatrix(predlda,testing$diagnosis)$overall
confusionMatrix(predlda,testing$diagnosis)$overall[1]
confusionMatrix(combPred,testing$diagnosis)$overall[1]
confusionMatrix(predrf,testing$diagnosis)$overall[1]
confusionMatrix(predgbm,testing$diagnosis)$overall[1]
confusionMatrix(predlda,testing$diagnosis)$overall[1]
confusionMatrix(combPred,testing$diagnosis)$overall
?confusionMatrix
library(AppliedPredictiveModeling)
library(caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
View(testing)
set.seed(233)
?set.seed
require(stats)
set.seed(3523)
library(AppliedPredictiveModeling)
library(caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
?enet
?plot.enet
?lasso
fit<-train(CompressiveStrength~.,data=training,method="lasso")
library(elasticnet)
?plot.enet
plot.enet(fit)
class(fit)
?enet
enet1<-enet(training[,-CompressiveStrength],training[,CompressiveStrength])
enet1<-enet(training[,-9],training[,9])
trainingM<-as.matrix(training)
View(trainingM)
enet1<-enet(trainingM[,-9],trainingM[,9])
plot.enet(enet1)
plot.enet(enet1)
?plot.enet
plot.enet(enet1,xvar="stpes")
plot.enet(enet1,xvar="step")
plot.enet(enet1,xvar="penalty")
plot.enet(enet1,xvar="penalty",use.color=T)
dat = read.csv("gaData.csv")
install.packages("forecast")
install.packages("lubridate")
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
View(testing)
View(training)
?bat
?bats
fit<-bats(tstrain)
class(fit)
pred<-predict(fit,testing)
View(testing)
pred<-predict(fit,testing$date)
fit
tstrain
?forecast
fcast<-forecast(fit,testing)
View(testing)
View(testing)
fcast<-forecast(fit,testing$date)
fcast<-forecast(fit,235,level=95)
fcst
fcast
View(testing)
View(training)
View(dat)
View(testing)
f<-forecast(fit,h=testing$X)
accuracy(fit,ts(testing$visitsTumblr))
View(dat)
View(training)
View(testing)
training<-training[251:365,]
?bats
Mod<-bats(tstrain)
Mod
?ets
plot(decompose(tstrain))
tstrain
tstrain = ts(training$visitsTumblr)
tstrain
?forecast
Mod<-bats(tstrain)
forecast(Mod)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")  # make sure the file in your working directory
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
# written code
library(forecast)
fit<-bats(tstrain)
fcast<-forecast(fit)
fcast
install.packages("e1071")
?e1071
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")  # make sure the file in your working directory
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
# written code
library(forecast)
fit<-bats(tstrain)
f<-forecast(fit,235,level=.95)
f
View(training)
training = dat[year(dat$date) < 2012,][251:365,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
fit<-bats(tstrain)
f<-forecast(fit,235,level=.95)
head(f)
f<-forecast(fit)
f
View(testing)
?forecast
f<-forecast(fit,20)
f
f<-forecast(fit,50)
f
f<-forecast(fit,109)
f
f<-forecast(fit,235)
f
count(testing$visitsTumblr>1021.6960)
table(testing$visitsTumblr>1021.6960)
8/235
227/235
f<-forecast(fit,235,level=95)
f
f$upper
table(testing$visitsTumblr<f$upper & testing$visitsTumblr>f$lower)
list.files()
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")
?randomforest
library(randomForest)
library(caret)
View(training)
View(testing)
View(testing)
names(testing)
testing$classe
names(testing)==names(training)
names(training)
is.nae(testing[,14])
table(is.na(training[,14]))
View(training)
training[1,14]
training[1,14]==""
table(is.na(training[,14])|training[,14]=="")
table(is.na(training[,14])|training[,14]=="")[2]
discard<-rep(NA,160)
discard<-rep(0,160)
For (i=1:160){
discard[i]<-table(is.na(training[,i])|training[,i]=="")[2]
}
For (i=1:160){
discard[i]<-table(is.na(training[,i])|training[,i]=="")[2]
}
for (i=1:160){
discard[i]<-table(is.na(training[,i])|training[,i]=="")[2]
}
for (i in 1:160){
discard[i]<-table(is.na(training[,i])|training[,i]=="")[2]
}
discard
training2<-training[discard==!"NA",]
training2<-training[,-discard==NA]
unique(discard)
training2<-training[,class(discard)==19216]
training2<-training[,discard==19216]
discard==19216
class(discard[17])
training2<-training[,class(discard)==numeric]
class(discard)==numeric
training2<-training[,discard==NA]
discard==NA
training2<-training[,is.na(discard)]
View(training2)
unique(training2$classe)
library(caret)
library(randomForest)
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")
discard<-rep(0,160)
for (i in 1:160){
discard[i]<-table(is.na(training[,i])|training[,i]=="")[2]
}
training2<-training[,is.na(discard)]
table(training2$new_window=="no")
library(caret)
library(randomForest)
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")
discard<-rep(0,160)
for (i in 1:160){
discard[i]<-table(is.na(training[,i])|training[,i]=="")[2]
}
training2<-training[,is.na(discard)]
training3<-training[,8:60]
View(training3)
View(training2)
training3<-training2[,8:60]
train<-training2[,8:60]
View(training3)
set.seed(233)
inuse <- createDataPartition(training3$classe, p = .75,
list = FALSE,
times = 1)
training4<-training3[-inuse,]
inuse <- createDataPartition(training3$classe, p = .80,
list = FALSE,
times = 1)
training4<-training3[-inuse,]
inuse <- createDataPartition(training3$classe, p = .85,
list = FALSE,
times = 1)
training4<-training3[-inuse,]
?randomForest
modFit1<-randomForest(classe~.,data=training4,ntree=100)
val<-training3[inuse,]
table(predcit(modFit1,val),val$classe)
table(predict(modFit1,val),val$classe)
confusionMatrix(predict(modFit1,val),val$classe)$overall
modFit1
modFit2<-train(classe~.data=training4)
modFit2<-train(classe~.,data=training4,method="rf")
names(training4)
testing2<-testing[,is.na(discard)]
testing3<-testing2[,8:60]
View(testing3)
names(testing3)==names(training4)
pred<-predict(modFit1,testing3)
pred
class(pred)
pred2<-as.charactor(pred)
pred2<-as.character(pred)
pred2
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(pred2)
modFit2<-randomForest(classe~.,data=training4,ntree=500)
modFit2
modFit2<-randomForest(classe~.,data=val,ntree=500)
modFit2
confusionMatrix(predict(modFit2,training4),training$classe)$overall[1]
confusionMatrix(predict(modFit2,training4),training4$classe)$overall[1]
pred<-predict(modFit2,testing3)
pred
training4<-training3[inuse,]
val<-training3[-inuse,]
modFit1<-randomForest(classe~.,data=training4,ntree=100)
modFit1
inuse <- createDataPartition(training3$classe, p = .5,
list = FALSE,
times = 1)
training4<-training3[inuse,]
val<-training3[-inuse,]
modFit1<-randomForest(classe~.,data=training4,ntree=500)
modFit
modFit1
modFit1<-randomForest(classe~.,data=training3,ntree=100)
modFit1
modFit1<-randomForest(classe~.,data=training3,ntree=500)
modFit1
View(training)
View(testing3)
View(testing)
View(testing3)
set.seed(3523)
library(AppliedPredictiveModeling)
library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
View(testing)
modFit<-svm(CompressiveStrength~.,data=training)
confusionMatrix(testing$CompressiveStrength,predict(modFit,testing))
modFit
predict(modFit,testing)
testing$CompressiveStrength
as.numeric(predict(modFit,testing))
confusionMatrix(testing$CompressiveStrength,as.numeric(predict(modFit,testing)))
pred<-as.numeric(predict(modFit,testing))
t<-testing$CompressiveStrength
class(pred)
confusionMatrix(pred,t)
class(predict(modFit,testing))
sqrt(1/255*sum((t-pred)^2)
)
sqrt(1/256*sum((t-pred)^2))
set.seed(325)
modFit<-svm(CompressiveStrength~.,data=training)
pred<-as.numeric(predict(modFit,testing))
sqrt(1/256*sum((t-pred)^2))
modFit<-train(CompressiveStrength~.,data=training,method="svm")
sqrt(1/255*sum((t-pred)^2))
set.seed(300)
modFit<-svm(CompressiveStrength~.,data=training)
sqrt(1/256*sum((t-pred)^2))
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")
discard<-rep(0,160)
for (i in 1:160){
discard[i]<-table(is.na(training[,i])|training[,i]=="")[2]
}
training2<-training[,is.na(discard)]
## remove irrelevant variables
training3<-training2[,8:60]
testing2<-testing[,is.na(discard)]
testing3<-testing2[,8:60]
library(caret)
library(randomForest)
trainIndex<-createDataPartition(training3$classe,p=0.5,list=F,times=1)
train<-training3[trainIndex,]
val<-training3[-trainIndex,]
modFit1<-randomForest(classe~.,data=train,ntree=500)
modFit1
confusionMatrix(predict(modFit1,val),val$classe)$overall[1]
confusionMatrix(predict(modFit1,val),val$classe)
?confusionMatrix
confusionMatrix(predict(modFit1,val),val$classe)$table
library(caret)
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")
discard<-rep(0,160)
for (i in 1:160){
discard[i]<-table(is.na(training[,i])|training[,i]=="")[2]
}
training2<-training[,is.na(discard)]
training3<-training2[,8:60]
testing2<-testing[,is.na(discard)]
testing3<-testing2[,8:60]
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
set.seed(825)
gbmFit1 <- train(classe ~ ., data = training3,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
library(caret)
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")
discard<-rep(0,160)
for (i in 1:160){
discard[i]<-table(is.na(training[,i])|training[,i]=="")[2]
}
training2<-training[,is.na(discard)]
training3<-training2[,8:60]
testing2<-testing[,is.na(discard)]
testing3<-testing2[,8:60]
library(randomForest)
set.seed(233)
View(testing2)
View(testing3)
View(training)
View(training3)
trainIndex<-createDataPartition(training3$classe,p=0.5,list=F,times=1)
train<-training3[trainIndex,]
val<-training3[-trainIndex,]
set.seed(2333)
modFit1<-randomForest(classe~.,data=train,ntree=500)
trainX<-train[,1:52]
trainY<-train[,53]
class(trainY)
class(as.vector(trainY))
trainY<-as.vector(train[,53])
result<-rfcv(trainX,trainY,cv.fold=10)
trainY<-train[,53]
result<-rfcv(trainX,trainY,cv.fold=10)
result<-rfcv(trainX,trainY,cv.fold=2)
result
summary(result)
result$error.cv
?rfcv
result2<-rfcv(trainX,trainY,mtry=c(52,26,13),cv.fold=3)
set.seed(233)
trainIndex<-createDataPartition(training3$classe,p=0.2,list=F,times=1)
train<-training3[trainIndex,]
fitControl <- trainControl(
method = "repeatedcv",
number = 5)
fit<-train(classe~.,data=train,method="rf", trControl = fitControl)
fit
confusionMatrix(predict(fit,train),train$classe)
confusionMatrix(predict(fit,val),val$classe)
result2<-rfcv(trainX,trainY,cv.fold=5)
result2<-rfcv(trainX,trainY,cv.fold=5,step=25)
result2$error.cv
result2<-rfcv(trainX,trainY,cv.fold=5,step=52)
result2$error.cv
result2$n.var
result2$predicted
control1 <- trainControl(method = "cv", number = 3, allowParallel = TRUE)
?proc.time
proc.time()
with(result, plot(n.var, error.cv, log="x", type="o", lwd=2))
with(result2, plot(n.var, error.cv, log="x", type="o", lwd=2))
library(knitr)
library(markdown)
knit('mlproject.Rmd')
